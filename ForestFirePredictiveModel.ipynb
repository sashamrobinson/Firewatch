{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e30724bc-ae76-4530-ad77-b45259f6814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Refer to \"ForestFireDataAnalysis.ipynb\" for data visualization to understand model\n",
    "\"\"\"\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9852829a-b4d3-4c32-8b3b-10a569aef6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Citation:\n",
    "# P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data.\n",
    "# In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence,\n",
    "# Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December,\n",
    "Guimaraes, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9.\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3f053136-4629-4151-aa15-9d7da5fe90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data for model by translating to booleans\n",
    "feats = ['month','day']\n",
    "data = pd.get_dummies(df,columns=feats,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9a9321a8-109a-4a65-b45c-29546c69b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove area field (this is the expected evaluative output)\n",
    "X = data.drop(['area'],axis=1).values\n",
    "y = data['area'].values\n",
    "\n",
    "# 80% of data for training, 20% for testing\n",
    "# X_train = training input values\n",
    "# y_train = training output values\n",
    "# X_test = testing input values\n",
    "# Y_test = testing output values\n",
    "training_inputs, testing_inputs, training_outputs, testing_outputs = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "722a4444-c7f1-4a4c-8f4a-4e1b299bc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to fit model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "training_inputs = sc.fit_transform(training_inputs)\n",
    "testing_inputs = sc.transform(testing_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c03c89b6-aff8-4297-85d5-478f526eaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning with keras using TensorFlow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Hidden layers are calculated as: (input_node_count + output_node_count) / 2 = 7\n",
    "\n",
    "model = Sequential([\n",
    "    keras.layers.Input(shape=(training_inputs.shape[1])), \n",
    "    keras.layers.Dense(7, kernel_initializer='uniform', activation='relu', input_dim=29),  \n",
    "    keras.layers.Dense(1, kernel_initializer = \"uniform\", activation = \"sigmoid\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "18673692-a60e-4a3a-b600-699c7c15f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.0072 - val_loss: 0.4082 - val_accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 0s 585us/step - loss: 0.4082 - accuracy: 0.0000e+00\n",
      "Mean Absolute Error on Test Data: 0.0\n",
      "4/4 [==============================] - 0s 461us/step\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "model.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "\n",
    "# Fitting model to data\n",
    "model.fit(training_inputs, training_outputs, batch_size = 10, epochs = 1, validation_data=(testing_inputs, testing_outputs))\n",
    "\n",
    "loss, mae = model.evaluate(testing_inputs, testing_outputs)\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "\n",
    "predictions = model.predict(testing_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e56e16eb-b6a0-4116-948b-fa17bd48b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy was 80.77%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for i in range(0, len(predictions)):\n",
    "    output = predictions[i]\n",
    "    expected_output = testing_outputs[i]\n",
    "\n",
    "    # Account for low amount of test data with generous margin of error\n",
    "    if expected_output > output - 7 and expected_output < output + 7:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "    # print(f\"Output: {predictions[i]}, Expected Output: {testing_outputs[i]}\")\n",
    "\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "print(f\"Accuracy was {round(accuracy, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b65d5-0ae7-466b-8c76-929e39b3c4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
